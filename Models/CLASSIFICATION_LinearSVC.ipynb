{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Support Vector Machine (SVM) is a powerful and versatile supervised learning algorithm used for both classification and regression tasks. It's a discriminative model that aims to find the best hyperplane in a high-dimensional space to separate different classes of data points.\n",
    "\n",
    "Here's a breakdown of key concepts within SVM:\n",
    "\n",
    "1. **Hyperplane:** In a two-dimensional space, a hyperplane is a line that divides the data points into two classes. In higher dimensions, a hyperplane becomes a multidimensional surface.\n",
    "\n",
    "2. **Support Vectors:** These are the data points closest to the hyperplane and influence its position and orientation. SVM aims to maximize the margin, which is the distance between the support vectors and the hyperplane.\n",
    "\n",
    "3. **Margin:** The margin is the distance between the hyperplane and the nearest data point from either class. SVM seeks to find the hyperplane with the maximum margin.\n",
    "\n",
    "4. **Kernel Trick:** SVM can handle non-linearly separable data by using a kernel function that maps the data into a higher-dimensional feature space. This allows the SVM to find a linearly separable hyperplane in this transformed space.\n",
    "    Common kernels include linear, polynomial, radial basis function (RBF), and sigmoid.\n",
    "\n",
    "5. **C Parameter:** It controls the trade-off between maximizing the margin and minimizing the classification error. A smaller C allows a larger margin but may misclassify more data, while a larger C penalizes misclassification more heavily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamters of SVM <br>\n",
    "`C` => inverse regularization strength <br>\n",
    "`kernel` => type of kernel <br>\n",
    "`gamma` => inverse RBF smoothness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
    "\n",
    "# Apply LinearSVC and print scores\n",
    "linearSVC = LinearSVC()\n",
    "linearSVC.fit(X_train, y_train)\n",
    "print(linearSVC.score(X_train, y_train))\n",
    "print(linearSVC.score(X_test, y_test))\n",
    "\n",
    "# Apply SVM and print scores\n",
    "non_linearSVC = SVC()\n",
    "non_linearSVC.fit(X_train, y_train)\n",
    "print(non_linearSVC.score(X_train, y_train))\n",
    "print(non_linearSVC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch to find the best hyperparamter `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an RBF SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "parameters = {'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
    "searcher = GridSearchCV(svm, parameters)\n",
    "searcher.fit(X_train,y_train)\n",
    "\n",
    "# Report the best parameters\n",
    "print(\"Best CV params\", searcher.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch to find the best hyperparamters <br>\n",
    "`gamma` & `C` which is responsible of regularization (min C means more regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an RBF SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "parameters = {'C':[0.1, 1, 10], 'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
    "searcher = GridSearchCV(svm, parameters)\n",
    "searcher.fit(X_train, y_train)\n",
    "\n",
    "# Report the best parameters and the corresponding score\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "print(\"Best CV accuracy\", searcher.best_score_)\n",
    "\n",
    "# Report the test accuracy using these best parameters\n",
    "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
