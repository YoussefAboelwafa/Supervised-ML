{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T15:50:04.288281900Z",
     "start_time": "2023-09-15T15:50:04.147691700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sales_df = pd.read_csv(\"datasets/advertising_and_sales_clean.csv\")\n",
    "music_df = pd.read_csv(\"datasets/music_clean.csv\")\n",
    "\n",
    "print(sales_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dummy variables\n",
    "\n",
    "#### Only applicable if one column has categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T15:50:04.303902400Z",
     "start_time": "2023-09-15T15:50:04.210178Z"
    }
   },
   "outputs": [],
   "source": [
    "sales_dummy = pd.get_dummies(sales_df, drop_first=True)\n",
    "print(sales_dummy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If more than one col of categorical data we will drop and concatinate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T15:50:04.303902400Z",
     "start_time": "2023-09-15T15:50:04.257039500Z"
    }
   },
   "outputs": [],
   "source": [
    "sales_dummy = pd.get_dummies(sales_df[\"influencer\"], drop_first=True)\n",
    "print(sales_dummy.head())\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "sales_dummy = pd.concat([sales_df, sales_dummy], axis=1)\n",
    "sales_dummy.drop(\"influencer\", axis=1, inplace=True)\n",
    "print(sales_dummy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Binarizing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T15:50:04.319523400Z",
     "start_time": "2023-09-15T15:50:04.288281900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert category to a binary feature\n",
    "sales_df[\"influencer\"] = np.where(sales_df[\"influencer\"] == 'Mega', 1, 0)\n",
    "print(sales_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T15:50:04.428874Z",
     "start_time": "2023-09-15T15:50:04.303902400Z"
    }
   },
   "outputs": [],
   "source": [
    "print(music_df.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sales_df.select_dtypes(exclude=['object'])\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get name of columns with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of columns with missing values\n",
    "cols_with_missing = [col for col in music_df.columns\n",
    "                     if music_df[col].isnull().any()]\n",
    "print(cols_with_missing)\n",
    "print(music_df.shape)\n",
    "\n",
    "# Drop columns in training and validation data\n",
    "reduced = music_df.drop(cols_with_missing, axis=1)\n",
    "print(reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T15:50:04.428874Z",
     "start_time": "2023-09-15T15:50:04.319523400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print all columns\n",
    "missing_values = music_df.isna().sum()\n",
    "print(missing_values)\n",
    "\n",
    "print(\"------------------------------------------------------\")\n",
    "# print only missing\n",
    "print(missing_values[missing_values>0])\n",
    "\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "music_df_clean = music_df.dropna()\n",
    "#or subset\n",
    "#music_df_clean = music_df.dropna(subset=['valence'])\n",
    "\n",
    "print(music_df_clean.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Impute missing values (Fill missing data)\n",
    "#### Must be split into numerical and categorical data\n",
    "- Fill with **Mean** for numerical data\n",
    "- Fill with **Mode** for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T15:50:04.428874Z",
     "start_time": "2023-09-15T15:50:04.335145500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_cat = music_df['genre'].values.reshape(-1, 1)\n",
    "X_num = music_df.drop(['popularity', 'genre'], axis=1).values\n",
    "y = music_df['popularity'].values\n",
    "\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(X_cat, y, test_size=0.2, random_state=12)\n",
    "\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=12)\n",
    "\n",
    "imp_cat = SimpleImputer(strategy='most_frequent')\n",
    "X_train_cat = imp_cat.fit_transform(X_train_cat)\n",
    "X_test_cat = imp_cat.transform(X_test_cat)\n",
    "\n",
    "imp_num = SimpleImputer(strategy='mean')\n",
    "X_train_num = imp_num.fit_transform(X_train_num)\n",
    "X_test_num = imp_num.transform(X_test_num)\n",
    "\n",
    "X_train = np.append(X_train_num, X_train_cat, axis=1)\n",
    "X_test = np.append(X_test_num, X_test_cat, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imputing with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T15:50:04.593429300Z",
     "start_time": "2023-09-15T15:50:04.350766100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = music_df.drop('popularity', axis=1).values\n",
    "y = music_df['popularity'].values\n",
    "\n",
    "steps = [('imputation', SimpleImputer()), ('logistic_regression', LogisticRegression())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
